{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWqcoPhU3RJN"
      },
      "source": [
        "# Breast Cancer Prediction\n",
        "\n",
        "In this exercise, you will train a neural network on the [Breast Cancer Dataset](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)) to predict if the tumor is malignant or benign.\n",
        "\n",
        "If you get stuck, we recommend that you review the ungraded labs for this week."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st5AIBFZ5mEQ"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JkMXve8XuN5X"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mticker\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUc3HpEQ5s6U"
      },
      "source": [
        "## Load and Preprocess the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-TQFUXu5wS_"
      },
      "source": [
        "We first download the dataset and create a data frame using pandas. We explicitly specify the column names because the CSV file does not have column headers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVh-W73J5TjS",
        "outputId": "65eed00c-a521-41f4-e7ad-c0403a459603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\n",
            "24576/19889 [=====================================] - 0s 0us/step\n",
            "32768/19889 [=================================================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "DATASET_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\"\n",
        "data_file = tf.keras.utils.get_file(\"breast_cancer.csv\", DATASET_URL)\n",
        "col_names = [\"id\", \"clump_thickness\", \"un_cell_size\", \"un_cell_shape\", \"marginal_adheshion\", \"single_eph_cell_size\", \"bare_nuclei\", \"bland_chromatin\", \"normal_nucleoli\", \"mitoses\", \"class\"]\n",
        "df = pd.read_csv(data_file, names=col_names, header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "XEv8vS_P6HaV",
        "outputId": "f7c48561-6ede-43b9-eb44-b609064807e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ff6ed891-a550-4fb6-91aa-f8711b83bd87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>clump_thickness</th>\n",
              "      <th>un_cell_size</th>\n",
              "      <th>un_cell_shape</th>\n",
              "      <th>marginal_adheshion</th>\n",
              "      <th>single_eph_cell_size</th>\n",
              "      <th>bare_nuclei</th>\n",
              "      <th>bland_chromatin</th>\n",
              "      <th>normal_nucleoli</th>\n",
              "      <th>mitoses</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000025</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002945</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015425</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1016277</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1017023</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff6ed891-a550-4fb6-91aa-f8711b83bd87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff6ed891-a550-4fb6-91aa-f8711b83bd87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff6ed891-a550-4fb6-91aa-f8711b83bd87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id  clump_thickness  un_cell_size  ...  normal_nucleoli  mitoses  class\n",
              "0  1000025                5             1  ...                1        1      2\n",
              "1  1002945                5             4  ...                2        1      2\n",
              "2  1015425                3             1  ...                1        1      2\n",
              "3  1016277                6             8  ...                7        1      2\n",
              "4  1017023                4             1  ...                1        1      2\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvvbnFL36L85"
      },
      "source": [
        "We have to do some preprocessing on the data. We first pop the id column since it is of no use for our problem at hand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDeXwHdA5uUN",
        "outputId": "a2b3dc56-4c68-4cfa-c5b5-605d2665db73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1000025\n",
              "1      1002945\n",
              "2      1015425\n",
              "3      1016277\n",
              "4      1017023\n",
              "        ...   \n",
              "694     776715\n",
              "695     841769\n",
              "696     888820\n",
              "697     897471\n",
              "698     897471\n",
              "Name: id, Length: 699, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.pop(\"id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubw5LueA6ZEY"
      },
      "source": [
        "Upon inspection of data, you can see that some values of the **bare_nuclei** column are unknown. We drop the rows with these unknown values. We also convert the **bare_nuclei** column to numeric. This is required for training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCcOrl1ITVhr",
        "outputId": "5c2b2967-a972-4d30-b021-ed78c5b6c51b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n"
          ]
        }
      ],
      "source": [
        "df = df[df[\"bare_nuclei\"] != '?' ]\n",
        "df.bare_nuclei = pd.to_numeric(df.bare_nuclei)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQMhcTQG7LzY"
      },
      "source": [
        "We check the class distribution of the data. You can see that there are two classes, 2.0 and 4.0\n",
        "According to the dataset:\n",
        "* **2.0 = benign**\n",
        "* **4.0 = malignant**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "SaAdQrBv8daS",
        "outputId": "a52b5210-6166-4fd9-d68a-5fcf455b8d09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efd716e7cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df['class'].hist(bins=20) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENjMKvxQ6sWy"
      },
      "source": [
        "We are going to model this problem as a binary classification problem which detects whether the tumor is malignant or not. Hence, we change the dataset so that:\n",
        "* **benign(2.0) = 0**\n",
        "* **malignant(4.0) = 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1MVzeUwf_A3E",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "df['class'] = np.where(df['class'] == 2, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGbKO1bR8S9h"
      },
      "source": [
        "We then split the dataset into training and testing sets. Since the number of samples is small, we will perform validation on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aNUy7JcuAXjC"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(df, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_ZKokUP8kP3"
      },
      "source": [
        "We get the statistics for training. We can look at statistics to get an idea about the distribution of plots. If you need more visualization, you can create additional data plots. We will also be using the mean and standard deviation from statistics for normalizing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k86tBT_QAm2P"
      },
      "outputs": [],
      "source": [
        "train_stats = train.describe()\n",
        "train_stats.pop('class')\n",
        "train_stats = train_stats.transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8AJ0Crc8u9t"
      },
      "source": [
        "We pop the class column from the training and test sets to create train and test outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V7EGUV-tA5LZ"
      },
      "outputs": [],
      "source": [
        "train_Y = train.pop(\"class\")\n",
        "test_Y = test.pop(\"class\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9wVRO5E9AgA"
      },
      "source": [
        "Here we normalize the data by using the formula: **X = (X - mean(X)) / StandardDeviation(X)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NDo__q_AA3j0"
      },
      "outputs": [],
      "source": [
        "def norm(x):\n",
        "    return (x - train_stats['mean']) / train_stats['std']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pdARlWaDA_8G"
      },
      "outputs": [],
      "source": [
        "norm_train_X = norm(train)\n",
        "norm_test_X = norm(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6LIVZbj9Usv"
      },
      "source": [
        "We now create Tensorflow datasets for training and test sets to easily be able to build and manage an input pipeline for our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1S0RtsP1Xsj8"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((norm_train_X.values, train_Y.values))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((norm_test_X.values, test_Y.values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Nb44PpV9hR4"
      },
      "source": [
        "We shuffle and prepare a batched dataset to be used for training in our custom training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "h9qdsNPen5-F"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(train)).batch(batch_size)\n",
        "\n",
        "test_dataset =  test_dataset.batch(batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM0TgIIFEW4o",
        "outputId": "76ab0762-22a5-4c89-f902-08ae14d42b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n"
          ]
        }
      ],
      "source": [
        "a = enumerate(train_dataset)\n",
        "\n",
        "print(len(list(a)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcbOJ6C79qT5"
      },
      "source": [
        "## Define the Model\n",
        "\n",
        "Now we will define the model. Here, we use the Keras Functional API to create a simple network of two `Dense` layers. We have modelled the problem as a binary classification problem and hence we add a single layer with sigmoid activation as the final layer of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HU3qcM9WBcMh"
      },
      "outputs": [],
      "source": [
        "def base_model():\n",
        "    inputs = tf.keras.layers.Input(shape=(len(train.columns)))\n",
        "\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(inputs)\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = base_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBhKIcKQ-Bwe"
      },
      "source": [
        "## Define Optimizer and Loss\n",
        "\n",
        "We use RMSprop optimizer and binary crossentropy as our loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "v5B3vh6fs84i"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "loss_object = tf.keras.losses.BinaryCrossentropy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSNDewgovSZ8"
      },
      "source": [
        "## Evaluate Untrained Model\n",
        "We calculate the loss on the model before training begins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUScS3GbtPXt",
        "outputId": "bee0089a-e4fa-463e-b9d7-4ce4b3f25c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss before training 0.7257\n"
          ]
        }
      ],
      "source": [
        "outputs = model(norm_test_X.values)\n",
        "loss_value = loss_object(y_true=test_Y.values, y_pred=np.expand_dims(outputs,1))\n",
        "print(\"Loss before training %.4f\" % loss_value.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPPb5ewkzMBY"
      },
      "source": [
        "We also plot the confusion matrix to visualize the true outputs against the outputs predicted by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ueenYwWZvQM_"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, title='', labels=[0,1]):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(cm)\n",
        "    plt.title(title)\n",
        "    fig.colorbar(cax)\n",
        "    ax.set_xticklabels([''] + labels)\n",
        "    ax.set_yticklabels([''] + labels)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "          plt.text(j, i, format(cm[i, j], fmt),\n",
        "                  horizontalalignment=\"center\",\n",
        "                  color=\"black\" if cm[i, j] > thresh else \"white\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "FApnBUNWv-ZR",
        "outputId": "2535ed46-2e42-4942-fde3-4325495928ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_confusion_matrix(test_Y.values, tf.round(outputs), title='Confusion Matrix for Untrained Model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-HTkbQb-gYp"
      },
      "source": [
        "## Define Metrics (Please complete this section)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYUyRka1-j87"
      },
      "source": [
        "### Define Custom F1Score Metric\n",
        "In this example, we will define a custom F1Score metric using the formula. \n",
        "\n",
        "**F1 Score = 2 * ((precision * recall) / (precision + recall))**\n",
        "\n",
        "**precision = true_positives / (true_positives + false_positives)**\n",
        "\n",
        "**recall = true_positives / (true_positives + false_negatives)**\n",
        "\n",
        "We use `confusion_matrix` defined in `tf.math` to calculate precision and recall.\n",
        "\n",
        "Here you can see that we have subclassed `tf.keras.Metric` and implemented the three required methods `update_state`, `result` and `reset_states`.\n",
        "\n",
        "### Please complete the result() method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PdUe6cqvbzXy"
      },
      "outputs": [],
      "source": [
        "class F1Score(tf.keras.metrics.Metric):\n",
        "\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        '''initializes attributes of the class'''\n",
        "        \n",
        "        # call the parent class init\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "\n",
        "        # Initialize Required variables\n",
        "        # true positives\n",
        "        self.tp = tf.Variable(0, dtype = 'int32')\n",
        "        # false positives\n",
        "        self.fp = tf.Variable(0, dtype = 'int32')\n",
        "        # true negatives\n",
        "        self.tn = tf.Variable(0, dtype = 'int32')\n",
        "        # false negatives\n",
        "        self.fn = tf.Variable(0, dtype = 'int32')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        '''\n",
        "        Accumulates statistics for the metric\n",
        "        \n",
        "        Args:\n",
        "            y_true: target values from the test data\n",
        "            y_pred: predicted values by the model\n",
        "        '''\n",
        "\n",
        "        # Calulcate confusion matrix.\n",
        "        conf_matrix = tf.math.confusion_matrix(y_true, y_pred, num_classes=2)\n",
        "        \n",
        "        # Update values of true positives, true negatives, false positives and false negatives from confusion matrix.\n",
        "        self.tn.assign_add(conf_matrix[0][0])\n",
        "        self.tp.assign_add(conf_matrix[1][1])\n",
        "        self.fp.assign_add(conf_matrix[0][1])\n",
        "        self.fn.assign_add(conf_matrix[1][0])\n",
        "\n",
        "    def result(self):\n",
        "        '''Computes and returns the metric value tensor.'''\n",
        "\n",
        "        # Calculate precision\n",
        "        if (self.tp + self.fp == 0):\n",
        "            precision = 1.0\n",
        "        else:\n",
        "            precision = self.tp / (self.tp + self.fp)\n",
        "      \n",
        "        # Calculate recall\n",
        "        if (self.tp + self.fn == 0):\n",
        "            recall = 1.0\n",
        "        else:\n",
        "            recall = self.tp / (self.tp + self.fn)\n",
        "\n",
        "        # Return F1 Score\n",
        "        ### START CODE HERE ###\n",
        "        f1_score =  2 * (precision * recall) / (precision + recall)\n",
        "        ### END CODE HERE ### \n",
        "        \n",
        "        return f1_score\n",
        "\n",
        "    def reset_states(self):\n",
        "        '''Resets all of the metric state variables.'''\n",
        "        \n",
        "        # The state of the metric will be reset at the start of each epoch.\n",
        "        self.tp.assign(0)\n",
        "        self.tn.assign(0) \n",
        "        self.fp.assign(0)\n",
        "        self.fn.assign(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC36oxgjEW4r",
        "outputId": "4ea5cdc6-6956-418f-bb0f-6f72e39ff274"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float64, numpy=0.2222222222222222>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Test Code:\n",
        "\n",
        "test_F1Score = F1Score()\n",
        "\n",
        "test_F1Score.tp = tf.Variable(2, dtype = 'int32')\n",
        "test_F1Score.fp = tf.Variable(5, dtype = 'int32')\n",
        "test_F1Score.tn = tf.Variable(7, dtype = 'int32')\n",
        "test_F1Score.fn = tf.Variable(9, dtype = 'int32')\n",
        "test_F1Score.result()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXBi0AtcEW4r"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```txt\n",
        "<tf.Tensor: shape=(), dtype=float64, numpy=0.2222222222222222>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiTa2CePAOTa"
      },
      "source": [
        "We initialize the seprate metrics required for training and validation. In addition to our custom F1Score metric, we are also using `BinaryAccuracy` defined in `tf.keras.metrics`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7Pa_x-5-CH_V"
      },
      "outputs": [],
      "source": [
        "train_f1score_metric = F1Score()\n",
        "val_f1score_metric = F1Score()\n",
        "\n",
        "train_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
        "val_acc_metric = tf.keras.metrics.BinaryAccuracy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1huOxRpEAxvf"
      },
      "source": [
        "## Apply Gradients (Please complete this section)\n",
        "\n",
        "The core of training is using the model to calculate the logits on specific set of inputs and compute the loss(in this case **binary crossentropy**) by comparing the predicted outputs to the true outputs. We then update the trainable weights using the optimizer algorithm chosen. The optimizer algorithm requires our computed loss and partial derivatives of loss with respect to each of the trainable weights to make updates to the same.\n",
        "\n",
        "We use gradient tape to calculate the gradients and then update the model trainable weights using the optimizer.\n",
        "\n",
        "### Please complete the following function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "MMPe25Dstn0v"
      },
      "outputs": [],
      "source": [
        "def apply_gradient(optimizer, loss_object, model, x, y):\n",
        "    '''\n",
        "    applies the gradients to the trainable model weights\n",
        "    \n",
        "    Args:\n",
        "        optimizer: optimizer to update model weights\n",
        "        loss_object: type of loss to measure during training\n",
        "        model: the model we are training\n",
        "        x: input data to the model\n",
        "        y: target values for each input\n",
        "    '''\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "    ### START CODE HERE ###\n",
        "        logits = model(x)\n",
        "        logits = np.asarray(logits).astype('float32').reshape((-1,1))\n",
        "        loss_value = loss_object(y_true=y, y_pred=logits)\n",
        "  \n",
        "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "    ### END CODE HERE ###\n",
        "  \n",
        "    return logits, loss_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N-_JbtgOEW4v",
        "outputId": "3ac2065b-aaea-4666-9503-8eacecd54892"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-50f39981b852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./test_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_test_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-033ff9118a74>\u001b[0m in \u001b[0;36mapply_gradient\u001b[0;34m(optimizer, loss_object, model, x, y)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \"\"\"\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n\u001b[0m\u001b[1;32m     74\u001b[0m                      f\"Provided `grads_and_vars` is {grads_and_vars}.\")\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: (['dense_24/kernel:0', 'dense_24/bias:0', 'dense_25/kernel:0', 'dense_25/bias:0', 'dense_26/kernel:0', 'dense_26/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'dense_24/kernel:0' shape=(9, 128) dtype=float32, numpy=\narray([[ 0.13755654, -0.10487851,  0.11320899, ...,  0.10674544,\n         0.0551021 , -0.07720634],\n       [-0.10526944,  0.18544538, -0.13544542, ..., -0.11742691,\n         0.16476552,  0.14791499],\n       [ 0.13539304, -0.00129975, -0.13119844, ...,  0.20392023,\n        -0.02359052, -0.17038697],\n       ...,\n       [-0.06590287,  0.10740338,  0.05995627, ..., -0.16363111,\n         0.05112846,  0.16904993],\n       [-0.1415501 , -0.03885564,  0.17053334, ..., -0.04159601,\n         0.05100243,  0.08285992],\n       [ 0.01516074, -0.00835484, -0.13360381, ...,  0.20048545,\n        -0.09838585, -0.05252422]], dtype=float32)>), (None, <tf.Variable 'dense_24/bias:0' shape=(128,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_25/kernel:0' shape=(128, 64) dtype=float32, numpy=\narray([[ 0.1211528 , -0.09807112, -0.09546527, ..., -0.03905942,\n         0.09311445,  0.10157533],\n       [ 0.10147314,  0.08142893, -0.07211427, ...,  0.14759456,\n         0.10412671, -0.09407593],\n       [-0.14751531, -0.15590477,  0.04163653, ...,  0.08450668,\n        -0.14830971,  0.17599405],\n       ...,\n       [ 0.08948143,  0.08236797,  0.07654436, ...,  0.01610911,\n        -0.11900167, -0.03387165],\n       [-0.09120663, -0.0585912 ,  0.01050666, ...,  0.16254206,\n        -0.00427365, -0.01388288],\n       [-0.0462901 , -0.01968144, -0.1210535 , ...,  0.07749744,\n         0.07698379,  0.09172894]], dtype=float32)>), (None, <tf.Variable 'dense_25/bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_26/kernel:0' shape=(64, 1) dtype=float32, numpy=\narray([[-0.06832482],\n       [-0.12553291],\n       [ 0.16270933],\n       [-0.22166952],\n       [ 0.01377159],\n       [ 0.22130305],\n       [-0.19193664],\n       [-0.10856946],\n       [ 0.0335049 ],\n       [-0.05059236],\n       [ 0.1525085 ],\n       [ 0.01186174],\n       [ 0.05778867],\n       [ 0.04098168],\n       [-0.23178613],\n       [ 0.26954097],\n       [-0.13214819],\n       [ 0.25155228],\n       [-0.20320323],\n       [ 0.05852479],\n       [ 0.2845245 ],\n       [ 0.10635418],\n       [-0.19337443],\n       [ 0.02901852],\n       [ 0.23112345],\n       [-0.20460466],\n       [ 0.05474421],\n       [ 0.1452305 ],\n       [-0.12810427],\n       [ 0.15138415],\n       [-0.09979874],\n       [ 0.13291198],\n       [ 0.06778806],\n       [-0.07375939],\n       [ 0.15852597],\n       [ 0.15800038],\n       [-0.14832398],\n       [ 0.28196937],\n       [-0.24139762],\n       [-0.2374267 ],\n       [-0.11828315],\n       [ 0.01057416],\n       [ 0.2168495 ],\n       [ 0.08723834],\n       [ 0.17856023],\n       [ 0.08524808],\n       [-0.1337345 ],\n       [-0.16379568],\n       [ 0.23298025],\n       [ 0.1352978 ],\n       [-0.00882989],\n       [ 0.18426797],\n       [-0.28344303],\n       [ 0.16272259],\n       [ 0.03807688],\n       [ 0.02006027],\n       [ 0.2643429 ],\n       [-0.25180098],\n       [ 0.08427837],\n       [ 0.2509395 ],\n       [ 0.2027092 ],\n       [-0.02479959],\n       [ 0.14511648],\n       [-0.0836491 ]], dtype=float32)>), (None, <tf.Variable 'dense_26/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>))."
          ]
        }
      ],
      "source": [
        "# Test Code:\n",
        "\n",
        "test_model = tf.keras.models.load_model('./test_model')\n",
        "test_logits, test_loss = apply_gradient(optimizer, loss_object, test_model, norm_test_X.values, test_Y.values)\n",
        "\n",
        "print(test_logits.numpy()[:8])\n",
        "print(test_loss.numpy())\n",
        "\n",
        "del test_model\n",
        "del test_logits\n",
        "del test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73H2PlS5EW4v"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "The output will be close to these values:\n",
        "```txt\n",
        "[[0.5516499 ]\n",
        " [0.52124363]\n",
        " [0.5412698 ]\n",
        " [0.54203206]\n",
        " [0.50022954]\n",
        " [0.5459626 ]\n",
        " [0.47841492]\n",
        " [0.54381996]]\n",
        "0.7030578\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYM6GZPjB40r"
      },
      "source": [
        "## Training Loop (Please complete this section)\n",
        "\n",
        "This function performs training during one epoch. We run through all batches of training data in each epoch to make updates to trainable weights using our previous function.\n",
        "You can see that we also call `update_state` on our metrics to accumulate the value of our metrics. \n",
        "\n",
        "We are displaying a progress bar to indicate completion of training in each epoch. Here we use `tqdm` for displaying the progress bar. \n",
        "\n",
        "### Please complete the following function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "3fHoh_hgz2PC"
      },
      "outputs": [],
      "source": [
        "def train_data_for_one_epoch(train_dataset, optimizer, loss_object, model, \n",
        "                             train_acc_metric, train_f1score_metric, verbose=True):\n",
        "    '''\n",
        "    Computes the loss then updates the weights and metrics for one epoch.\n",
        "    \n",
        "    Args:\n",
        "        train_dataset: the training dataset\n",
        "        optimizer: optimizer to update model weights\n",
        "        loss_object: type of loss to measure during training\n",
        "        model: the model we are training\n",
        "        train_acc_metric: calculates how often predictions match labels\n",
        "        train_f1score_metric: custom metric we defined earlier\n",
        "    '''\n",
        "    losses = []\n",
        "\n",
        "    #Iterate through all batches of training data\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "\n",
        "        #Calculate loss and update trainable variables using optimizer\n",
        "        ### START CODE HERE ###\n",
        "        logits, loss = apply_gradient(optimizer, loss_object, model, x_batch_train, y_batch_train)\n",
        "        losses.append(loss)        \n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        #Round off logits to nearest integer and cast to integer for calulating metrics\n",
        "        ### START CODE HERE ###\n",
        "        logits = tf.round(logits)\n",
        "        logits = tf.cast(logits, 'int64')\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        #Update the training metrics\n",
        "        ### START CODE HERE ###\n",
        "        train_acc_metric.update_state(y_batch_train, logits)\n",
        "        train_f1score_metric.update_state(y_batch_train, logits)\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        #Update progress\n",
        "        if verbose:\n",
        "            print(\"Training loss for step %s: %.4f\" % (int(step), float(loss_value)))\n",
        "    \n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7a-d1n43EW4w",
        "outputId": "cab3e105-4a24-45f4-9659-c63297d07d98"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-897105dccc30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m test_losses = train_data_for_one_epoch(train_dataset, optimizer, loss_object, test_model, \n\u001b[0;32m----> 6\u001b[0;31m                              train_acc_metric, train_f1score_metric, verbose=False)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-5c51b22c9562>\u001b[0m in \u001b[0;36mtrain_data_for_one_epoch\u001b[0;34m(train_dataset, optimizer, loss_object, model, train_acc_metric, train_f1score_metric, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#Calculate loss and update trainable variables using optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m### START CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-033ff9118a74>\u001b[0m in \u001b[0;36mapply_gradient\u001b[0;34m(optimizer, loss_object, model, x, y)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \"\"\"\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n\u001b[0m\u001b[1;32m     74\u001b[0m                      f\"Provided `grads_and_vars` is {grads_and_vars}.\")\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: (['dense_24/kernel:0', 'dense_24/bias:0', 'dense_25/kernel:0', 'dense_25/bias:0', 'dense_26/kernel:0', 'dense_26/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'dense_24/kernel:0' shape=(9, 128) dtype=float32, numpy=\narray([[ 0.13755654, -0.10487851,  0.11320899, ...,  0.10674544,\n         0.0551021 , -0.07720634],\n       [-0.10526944,  0.18544538, -0.13544542, ..., -0.11742691,\n         0.16476552,  0.14791499],\n       [ 0.13539304, -0.00129975, -0.13119844, ...,  0.20392023,\n        -0.02359052, -0.17038697],\n       ...,\n       [-0.06590287,  0.10740338,  0.05995627, ..., -0.16363111,\n         0.05112846,  0.16904993],\n       [-0.1415501 , -0.03885564,  0.17053334, ..., -0.04159601,\n         0.05100243,  0.08285992],\n       [ 0.01516074, -0.00835484, -0.13360381, ...,  0.20048545,\n        -0.09838585, -0.05252422]], dtype=float32)>), (None, <tf.Variable 'dense_24/bias:0' shape=(128,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_25/kernel:0' shape=(128, 64) dtype=float32, numpy=\narray([[ 0.1211528 , -0.09807112, -0.09546527, ..., -0.03905942,\n         0.09311445,  0.10157533],\n       [ 0.10147314,  0.08142893, -0.07211427, ...,  0.14759456,\n         0.10412671, -0.09407593],\n       [-0.14751531, -0.15590477,  0.04163653, ...,  0.08450668,\n        -0.14830971,  0.17599405],\n       ...,\n       [ 0.08948143,  0.08236797,  0.07654436, ...,  0.01610911,\n        -0.11900167, -0.03387165],\n       [-0.09120663, -0.0585912 ,  0.01050666, ...,  0.16254206,\n        -0.00427365, -0.01388288],\n       [-0.0462901 , -0.01968144, -0.1210535 , ...,  0.07749744,\n         0.07698379,  0.09172894]], dtype=float32)>), (None, <tf.Variable 'dense_25/bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_26/kernel:0' shape=(64, 1) dtype=float32, numpy=\narray([[-0.06832482],\n       [-0.12553291],\n       [ 0.16270933],\n       [-0.22166952],\n       [ 0.01377159],\n       [ 0.22130305],\n       [-0.19193664],\n       [-0.10856946],\n       [ 0.0335049 ],\n       [-0.05059236],\n       [ 0.1525085 ],\n       [ 0.01186174],\n       [ 0.05778867],\n       [ 0.04098168],\n       [-0.23178613],\n       [ 0.26954097],\n       [-0.13214819],\n       [ 0.25155228],\n       [-0.20320323],\n       [ 0.05852479],\n       [ 0.2845245 ],\n       [ 0.10635418],\n       [-0.19337443],\n       [ 0.02901852],\n       [ 0.23112345],\n       [-0.20460466],\n       [ 0.05474421],\n       [ 0.1452305 ],\n       [-0.12810427],\n       [ 0.15138415],\n       [-0.09979874],\n       [ 0.13291198],\n       [ 0.06778806],\n       [-0.07375939],\n       [ 0.15852597],\n       [ 0.15800038],\n       [-0.14832398],\n       [ 0.28196937],\n       [-0.24139762],\n       [-0.2374267 ],\n       [-0.11828315],\n       [ 0.01057416],\n       [ 0.2168495 ],\n       [ 0.08723834],\n       [ 0.17856023],\n       [ 0.08524808],\n       [-0.1337345 ],\n       [-0.16379568],\n       [ 0.23298025],\n       [ 0.1352978 ],\n       [-0.00882989],\n       [ 0.18426797],\n       [-0.28344303],\n       [ 0.16272259],\n       [ 0.03807688],\n       [ 0.02006027],\n       [ 0.2643429 ],\n       [-0.25180098],\n       [ 0.08427837],\n       [ 0.2509395 ],\n       [ 0.2027092 ],\n       [-0.02479959],\n       [ 0.14511648],\n       [-0.0836491 ]], dtype=float32)>), (None, <tf.Variable 'dense_26/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>))."
          ]
        }
      ],
      "source": [
        "# TEST CODE\n",
        "\n",
        "test_model = tf.keras.models.load_model('./test_model')\n",
        "\n",
        "test_losses = train_data_for_one_epoch(train_dataset, optimizer, loss_object, test_model, \n",
        "                             train_acc_metric, train_f1score_metric, verbose=False)\n",
        "\n",
        "for test_loss in test_losses:\n",
        "    print(test_loss.numpy())\n",
        "\n",
        "del test_model\n",
        "del test_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GtfQ5CUEW4w"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "The losses should generally be decreasing and will start from around 0.75. For example:\n",
        "\n",
        "```\n",
        "0.7600615\n",
        "0.6092045\n",
        "0.5525634\n",
        "0.4358902\n",
        "0.4765755\n",
        "0.43327087\n",
        "0.40585428\n",
        "0.32855004\n",
        "0.35755336\n",
        "0.3651728\n",
        "0.33971977\n",
        "0.27372319\n",
        "0.25026917\n",
        "0.29229593\n",
        "0.242178\n",
        "0.20602849\n",
        "0.15887335\n",
        "0.090397514\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9RJq8BLCsSF"
      },
      "source": [
        "At the end of each epoch, we have to validate the model on the test dataset. The following function calculates the loss on test dataset and updates the states of the validation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "5gLJyAJE0YRc"
      },
      "outputs": [],
      "source": [
        "def perform_validation():\n",
        "    losses = []\n",
        "\n",
        "    #Iterate through all batches of validation data.\n",
        "    for x_val, y_val in test_dataset:\n",
        "\n",
        "        #Calculate validation loss for current batch.\n",
        "        val_logits = model(x_val) \n",
        "        val_loss = loss_object(y_true=y_val, y_pred=val_logits)\n",
        "        losses.append(val_loss)\n",
        "\n",
        "        #Round off and cast outputs to either  or 1\n",
        "        val_logits = tf.cast(tf.round(model(x_val)), 'int64')\n",
        "\n",
        "        #Update validation metrics\n",
        "        val_acc_metric.update_state(y_val, val_logits)\n",
        "        val_f1score_metric.update_state(y_val, val_logits)\n",
        "        \n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLymSCkUC-CL"
      },
      "source": [
        "Next we define the training loop that runs through the training samples repeatedly over a fixed number of epochs. Here we combine the functions we built earlier to establish the following flow:\n",
        "1. Perform training over all batches of training data.\n",
        "2. Get values of metrics.\n",
        "3. Perform validation to calculate loss and update validation metrics on test data.\n",
        "4. Reset the metrics at the end of epoch.\n",
        "5. Display statistics at the end of each epoch.\n",
        "\n",
        "**Note** : We also calculate the training and validation losses for the whole epoch at the end of the epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OOO1x3VyuPUV",
        "outputId": "caffbdb4-af61-4a76-d324-bdc80e546205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of epoch 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-01cb494120cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#Perform Training over all batches of train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     losses_train = train_data_for_one_epoch(train_dataset, optimizer, loss_object, model, \n\u001b[0;32m----> 9\u001b[0;31m                              train_acc_metric, train_f1score_metric)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Get results from training metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-5c51b22c9562>\u001b[0m in \u001b[0;36mtrain_data_for_one_epoch\u001b[0;34m(train_dataset, optimizer, loss_object, model, train_acc_metric, train_f1score_metric, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#Calculate loss and update trainable variables using optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m### START CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-033ff9118a74>\u001b[0m in \u001b[0;36mapply_gradient\u001b[0;34m(optimizer, loss_object, model, x, y)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \"\"\"\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n\u001b[0m\u001b[1;32m     74\u001b[0m                      f\"Provided `grads_and_vars` is {grads_and_vars}.\")\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: (['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'dense/kernel:0' shape=(9, 128) dtype=float32, numpy=\narray([[ 0.13082726, -0.19884971,  0.20701618, ...,  0.10104041,\n         0.13505359, -0.13020593],\n       [-0.04041979,  0.04547353,  0.07110815, ...,  0.17359923,\n        -0.1161974 , -0.15939593],\n       [-0.0343214 ,  0.01088081, -0.06201272, ...,  0.14761557,\n        -0.03228958, -0.14364493],\n       ...,\n       [ 0.14315991,  0.09318896, -0.15576679, ...,  0.08308075,\n         0.03400657,  0.10588969],\n       [-0.17505203, -0.1484282 ,  0.13195069, ...,  0.06937061,\n         0.01564138,  0.20718803],\n       [-0.1918816 ,  0.04489122, -0.00607929, ...,  0.20887588,\n        -0.1136359 ,  0.16671191]], dtype=float32)>), (None, <tf.Variable 'dense/bias:0' shape=(128,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_1/kernel:0' shape=(128, 64) dtype=float32, numpy=\narray([[ 0.04928391,  0.00605249, -0.00905003, ...,  0.08279471,\n        -0.03543842,  0.12389906],\n       [-0.05419642,  0.00149702, -0.14559427, ...,  0.00955588,\n        -0.10105351, -0.06266166],\n       [-0.0624918 ,  0.17505024,  0.13509561, ...,  0.10165884,\n         0.05889001,  0.1731988 ],\n       ...,\n       [ 0.03238024,  0.02444513, -0.13937381, ...,  0.01946329,\n        -0.04103914,  0.03785773],\n       [ 0.01254687,  0.1224172 , -0.07707474, ..., -0.14841005,\n         0.16711272, -0.07026617],\n       [ 0.0527212 ,  0.01116243,  0.15887807, ..., -0.09341423,\n         0.01092441, -0.05822511]], dtype=float32)>), (None, <tf.Variable 'dense_1/bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_2/kernel:0' shape=(64, 1) dtype=float32, numpy=\narray([[-0.26552513],\n       [-0.19978704],\n       [-0.14480834],\n       [ 0.11817545],\n       [-0.24379513],\n       [ 0.18611604],\n       [ 0.10086277],\n       [ 0.03828964],\n       [ 0.15284547],\n       [-0.29013684],\n       [-0.20684797],\n       [ 0.2931354 ],\n       [ 0.08643183],\n       [ 0.12230498],\n       [ 0.02124077],\n       [-0.21905725],\n       [ 0.10200849],\n       [ 0.18722129],\n       [ 0.06469703],\n       [ 0.15284953],\n       [ 0.07902786],\n       [-0.0019066 ],\n       [ 0.09166706],\n       [-0.06814829],\n       [-0.12899329],\n       [-0.15394978],\n       [ 0.01770818],\n       [ 0.07957569],\n       [ 0.252092  ],\n       [ 0.30025977],\n       [ 0.28744608],\n       [-0.27726474],\n       [-0.15565428],\n       [ 0.05190754],\n       [ 0.0006136 ],\n       [ 0.20444876],\n       [-0.27958634],\n       [ 0.07386652],\n       [ 0.29397422],\n       [ 0.25540572],\n       [-0.23136547],\n       [-0.1013407 ],\n       [ 0.11793444],\n       [ 0.13743037],\n       [ 0.21470004],\n       [ 0.12440914],\n       [ 0.10514688],\n       [ 0.01760423],\n       [ 0.26160222],\n       [ 0.05601659],\n       [ 0.04817697],\n       [ 0.0870963 ],\n       [ 0.07832232],\n       [-0.20082158],\n       [ 0.15676156],\n       [ 0.19397429],\n       [ 0.04165989],\n       [ 0.20574749],\n       [-0.2199569 ],\n       [-0.21866007],\n       [-0.15361519],\n       [ 0.13927966],\n       [-0.19540331],\n       [-0.22759074]], dtype=float32)>), (None, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>))."
          ]
        }
      ],
      "source": [
        "# Iterate over epochs.\n",
        "epochs = 5\n",
        "epochs_val_losses, epochs_train_losses = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('Start of epoch %d' % (epoch,))\n",
        "    #Perform Training over all batches of train data\n",
        "    losses_train = train_data_for_one_epoch(train_dataset, optimizer, loss_object, model, \n",
        "                             train_acc_metric, train_f1score_metric)\n",
        "\n",
        "    # Get results from training metrics\n",
        "    train_acc = train_acc_metric.result()\n",
        "    train_f1score = train_f1score_metric.result()\n",
        "\n",
        "    #Perform validation on all batches of test data\n",
        "    losses_val = perform_validation()\n",
        "\n",
        "    # Get results from validation metrics\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_f1score = val_f1score_metric.result()\n",
        "\n",
        "    #Calculate training and validation losses for current epoch\n",
        "    losses_train_mean = np.mean(losses_train)\n",
        "    losses_val_mean = np.mean(losses_val)\n",
        "    epochs_val_losses.append(losses_val_mean)\n",
        "    epochs_train_losses.append(losses_train_mean)\n",
        "\n",
        "    print('\\n Epcoh %s: Train loss: %.4f  Validation Loss: %.4f, Train Accuracy: %.4f, Validation Accuracy %.4f, Train F1 Score: %.4f, Validation F1 Score: %.4f' % (epoch, float(losses_train_mean), float(losses_val_mean), float(train_acc), float(val_acc), train_f1score, val_f1score))\n",
        "\n",
        "    #Reset states of all metrics\n",
        "    train_acc_metric.reset_states()\n",
        "    val_acc_metric.reset_states()\n",
        "    val_f1score_metric.reset_states()\n",
        "    train_f1score_metric.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoLxueMdzm14"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EGW3HVUzqBX"
      },
      "source": [
        "### Plots for Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8Wsr6wG0T4h"
      },
      "source": [
        "We plot the progress of loss as training proceeds over number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "MsmF_2n307SP",
        "outputId": "03a0ff86-48e9-4842-8722-67a41efccc13"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def plot_metrics(train_metric, val_metric, metric_name, title, ylim=5):\n",
        "    plt.title(title)\n",
        "    plt.ylim(0,ylim)\n",
        "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
        "    plt.plot(train_metric,color='blue',label=metric_name)\n",
        "    plt.plot(val_metric,color='green',label='val_' + metric_name)\n",
        "\n",
        "plot_metrics(epochs_train_losses, epochs_val_losses, \"Loss\", \"Loss\", ylim=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27fXX7Yqyu5S"
      },
      "source": [
        "We plot the confusion matrix to visualize the true values against the values predicted by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "_9n2XJ9MwpDS",
        "outputId": "8f1e0f47-e6cf-426f-fa08-db50f86872bd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "test_outputs = model(norm_test_X.values)\n",
        "plot_confusion_matrix(test_Y.values, tf.round(test_outputs), title='Confusion Matrix for Untrained Model')"
      ]
    }
  ],
  "metadata": {
    "coursera": {
      "schema_names": [
        "TF3C2W2-1",
        "TF3C2W2-2",
        "TF3C2W2-3"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "C2W2_Assignment.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}